{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subspace Inference for Bayesian Neural Network UsingÂ Julia\n",
    "\n",
    "### Introduction to uncertainty analysis in Deep Neural Network (DNN)\n",
    "\n",
    "Deep learning has led to a revolution in artificial intelligence, that has artificial neural networks capable of tackling more and more complex and challenging problems. The learning in this s networks can be supervised or unsupervised. However, there is a chance of overfitting in deep learning models. The Bayesian neural networks use Bayesian techniques to extract these uncertainties.\n",
    "\n",
    "### Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sciweavers.org/tex2img.php?eq=P%28A%7CB%29%20%3D%20%5Cfrac%7BP%28A%29%2AP%28B%7CA%29%7D%7BP%28B%29%7D&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0\" align=\"center\" border=\"0\" alt=\"P(A|B) = \\frac{P(A)*P(B|A)}{P(B)}\" width=\"190\" height=\"46\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem depends on the prior probability distributions and the likelihood value s to calculate the posterior probability. The posterior probability P(A|B) is proportional to prior and the likelihood probability distribution in the above equation. P(A|B) and P(B|A) is also called a conditional probability, and P(A) and P(B) is called marginal probability. P(B) calculation is a tedious process; therefore, approximate Bayesian inference is introduced. In approximate Bayesian inference, the posterior probability will be proportional to the product of prior probability distribution and the likelihood distribution. Similarly, the prior probability will be proportional to joint probability. The MCMC methods are used to sample from the posterior distribution using a joint probability distribution.\n",
    "\n",
    "### Bayesian Neural Network(BNN)\n",
    "\n",
    "Simply a BNN is a stochastic neural network trained using Bayesian inference methods.In BNN, the parameters are defined as a distribution instead of a single value as in the figure below:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
