#Subspace Inference for Bayesian Deep Learning

This package aims to generate the subspace and subspace inferences.

The subspace can be generated by using the following commands:
```julia
	using SubspaceInference
	W_swa,P = subspace(model, shape, cost, data, opt, callback;T = 10, η = 0.1, c = 1, M = 2, svd_len = 1)
```

This work is implemented by referring the folloing publication:
Izmailov, P., Maddox, W. J., Kirichenko, P., Garipov, T., Vetrov, D., & Wilson, A. G. (2020, August). Subspace
  inference for Bayesian deep learning. In Uncertainty in Artificial Intelligence (pp. 1169-1179). PMLR.


## Input Arguments
- `model` : Machine learning model. Eg: Chain(Dense(10,2)). Model should be created with Chain in Flux
- `shape` : Shape of the neural network layer. Eg: shape =[((2,10),2)] based on above model. The type of shape should be Array{Tuple{Tuple{Int64,Int64},Int64},1}
- `cost` : Cost function. Eg: L(x, y) = Flux.Losses.mse(m(x), y)
- `data` : Inputs and outputs. Eg:	X = rand(10); Y = rand(2); data = Iterators.repeated((X,Y),100);
- `opt`	: Optimzer. Eg: opt = ADAM(0.1)
- `callback` : Callback function during training. Eg: callback() = @show(L(X,Y))

## Keyword Arguments
- `T` : Number of steps for subspace calculation. Eg: T= 1
- `c` : Moment update frequency. Eg: c = 1
- `M` : Maximum number of columns in deviation matrix. Eg: M= 2
- `svd_len`: Number of columns in right singukar vectors during SVD. Eg; svd_len = 1

## Outputs
- `W_swa`: Mean weights
- `P` : Projection Matrix


## Example
```julia
julia> using SubspaceInference
julia> using Flux
julia> using Flux: @epochs

julia> M = 10
10

julia> N = 15
15

julia> O = 2
2

julia>

julia> shape =[((2,M),O)]
1-element Array{Tuple{Tuple{Int64,Int64},Int64},1}:
 ((2, 10), 2)

julia>

julia> X = rand(M)
10-element Array{Float64,1}:
 0.7737119455842942
 0.14428484406420816
 0.22122042747968074
 0.9241766105537694
 0.6215123938104565
 0.6756997077531242
 0.12785804311549986
 0.150711126348674
 0.4183913824527177
 0.6332452820863166

julia> Y = rand(O)
2-element Array{Float64,1}:
 0.7516588782590106
 0.6885491912398543

julia> data = Iterators.repeated((X,Y),N)
Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,1},Array{Float64,1}}}}(Base.Iterators.Repeated{Tuple{Array{Float64,1},Array{Float64,1}}}(([0.7737119455842942, 0.14428484406420816, 0.22122042747968074, 0.9241766105537694, 0.6215123938104565, 0.6756997077531242, 0.12785804311549986, 0.150711126348674, 0.4183913824527177, 0.6332452820863166], [0.7516588782590106, 0.6885491912398543])), 15)

julia> m = Chain(Dense(M, O))
Chain(Dense(10, 2))

julia>

julia> L(x, y) = Flux.Losses.mse(m(x), y)
L (generic function with 1 method)

julia> ps = Flux.params(m)
Params([Float32[0.67735904 0.4369507 … -0.10510749 0.70252454; -0.61290014 -0.2520061 … 0.64106333 0.64954597], Float32[0.0, 0.0]])

julia>

julia> opt = ADAM(0.1)
ADAM(0.1, (0.9, 0.999), IdDict{Any,Any}())

julia>

julia> callback() = @show(L(X,Y))
callback (generic function with 1 method)

julia> @epochs 1 Flux.train!(L, ps, data, opt, cb = () -> callback())
[ Info: Epoch 1
L(X, Y) = 0.04521163525801487
L(X, Y) = 0.08661385049873213
L(X, Y) = 0.12712039750119675
L(X, Y) = 0.11094914500538869
L(X, Y) = 0.06632368577274748
L(X, Y) = 0.01925734266348062
L(X, Y) = 0.011562931837724891
L(X, Y) = 0.04376509466277575
L(X, Y) = 0.07109118527278957
L(X, Y) = 0.06060438990147349
L(X, Y) = 0.02641751464849993
L(X, Y) = 0.0029559378669315106
L(X, Y) = 0.0063843590923475906
L(X, Y) = 0.023513481702189067
L(X, Y) = 0.033099189299330076

julia> itr = 5
5
julia> c = 1 #moment update frequency
1
julia> M = 2#maximum number of coulmns in deviation matrix
2
julia> svd_len = 3 #number of columns in svd
3
julia> w_cap, P = subspace(m, shape, L, data, opt, callback)
L(X, Y) = 0.02867851268298835
L(X, Y) = 0.017968021218157035
L(X, Y) = 0.009384544741520551
L(X, Y) = 0.005519740772588515
L(X, Y) = 0.006446343917680938
L(X, Y) = 0.01118980108797052
L(X, Y) = 0.01586931231093341
L(X, Y) = 0.015250931142607458
L(X, Y) = 0.008489534565086162
L(X, Y) = 0.00148606387215166
L(X, Y) = 0.0007221237551106829
L(X, Y) = 0.00569273057489411
L(X, Y) = 0.009800227783640083
L(X, Y) = 0.008549077076642864
L(X, Y) = 0.0040731403261321

([0.731077416376634, -0.48140240528366784, 0.49066919359293854, -0.1205082738941366, -0.6308706565336748, 0.8200040622190996, 0.14871671524914828, -0.37537242336706683, -0.17135486548597162, -0.0013433045876974409  …  -0.21829429675232281, 0.7728561867367137, 0.7357346252961592, 0.4681728644804521, -0.05138901925899766, 0.7725611491636797, 0.7562429146333174, 0.7810437841848894, 0.053718484599481926, 0.13149788162925027], [-2.444666981930138 -2.418336020361015])

```