{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subspace Inference\n",
    "\n",
    "Byesisan inference methods are used to generate uncertainty informations in Neural Networks (DNN). However, usingBayesian inference in Deep Neural network is challenging due to large dimension of parameter space. Subspace inference method is used to reduce generate uncertainty information from subspace of DNN paramter space.\n",
    "\n",
    "Subspace Inference package is implemented based on\n",
    "\n",
    "Izmailov, P., Maddox, W. J., Kirichenko, P., Garipov, T., Vetrov, D., & Wilson, A. G. (2020, August). Subspace inference for Bayesian deep learning. In Uncertainty in Artificial Intelligence (pp. 1169-1179). PMLR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains uncertainty generation of simple multilayer perceptron\n",
    "The is DNN contains 2 inputs and one outputs. The hidden layer sizes are as follows [200 50 50]\n",
    "\n",
    "Start using subspace inference using in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use packages\n",
    "using IJulia\n",
    "IJulia.installkernel(\"Julia nodeps\", \"--depwarn=no\")\n",
    "using NPZ\n",
    "using Plots\n",
    "using Flux\n",
    "using Flux: Data.DataLoader\n",
    "using Flux: @epochs\n",
    "using Plots\n",
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using Zygote\n",
    "using Statistics\n",
    "using SubspaceInference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set root of project folder\n",
    "This folder contains data and trained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pwd();\n",
    "cd(root);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data\n",
    "This loaded data conatains two columns, one is taken as <em>x</em> and <em>y</em>. The <em>x</em>  is converted to features using <em>features</em> function. Then zipped using <em>DataLoader</em> available with <em>Flux</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laod data\n",
    "data_ld = npzread(\"data.npy\");\n",
    "x, y = (data_ld[:, 1]', data_ld[:, 2]');\n",
    "function features(x)\n",
    "    return vcat(x./2, (x./2).^2)\n",
    "end\n",
    "\n",
    "f = features(x);\n",
    "data =  DataLoader(f,y, batchsize=50, shuffle=true);\n",
    "\n",
    "#plot data\n",
    "scatter(data_ld[:,1],data_ld[:,2],color=[\"red\"], title=\"Dataset\", legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Model setup\n",
    "Simple multilayer perceptron is created as using <em>Dense</em> layer. This DNN conatains 2 inputs, 1 output and hidden layers of [200,50,50] size. All layers other than output layer contains ***ReLu*** activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "\t\tDense(2,200,Flux.relu), \n",
    "\t\tDense(200,50,Flux.relu),\n",
    "\t\tDense(50,50,Flux.relu),\n",
    "\t\tDense(50,50,Flux.relu),\n",
    "\t\tDense(50,1),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is destructed to extract weights and function as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Î¸, re = Flux.destructure(m);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "Gaussian likelihood cost function is implemented for training as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L(x, y) = Flux.Losses.mse(m(x), y)/2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are load as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = Flux.params(m);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Optimzer used in this project is Stochastic gradient descent with momentum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Momentum(0.01, 0.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain weights ad save\n",
    "The DNN needs to pretrains and save for subsce inference as below. NB: training takes little time. This package examppes contain some trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 3000\n",
    "# for j in 1:5\n",
    "#    m = Chain(\n",
    "#            Dense(2,200,Flux.relu),\n",
    "#            Dense(200,50,Flux.relu),\n",
    "#            Dense(50,50,Flux.relu),\n",
    "#            Dense(50,50,Flux.relu),\n",
    "#            Dense(50,1),\n",
    "#    )\n",
    "#    ps = Flux.params(m)\n",
    "#    SubspaceInference.pretrain(epochs, L, ps, data, opt, lr_init =0.01, print_freq= 100)\n",
    "#    @save \"model_weights_$(j).bson\" ps\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot different SGD solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = collect(range(-10.0, 10.0,length = 100))\n",
    "inp = features(z')\n",
    "trajectories = Array{Float64}(undef,100,5)\n",
    "for i in 1:5\n",
    "\t@load \"model_weights_$(i).bson\" ps\n",
    "\tFlux.loadparams!(m, ps)\n",
    "\tout = m(inp)\n",
    "\ttrajectories[:, i] = out'\n",
    "end\n",
    "SubspaceInference.plot_predictive(data_ld, trajectories, z, title=\"SGD Solutions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained weight\n",
    "The pretrained weights can be found in examples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1;\n",
    "@load \"model_weights_$(i).bson\" ps;\n",
    "Flux.loadparams!(m, ps);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate uncertainty of weights using\n",
    "<em>weight_uncertainty</em> function from ***SubspaceInference*** package is used to generate uncertainty of parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10 #Rank of PCA or Maximum columns in deviation matrix\n",
    "T = 10 #Steps\n",
    "itr = 100\n",
    "all_chain = SubspaceInference.weight_uncertainty(m, L, data, opt, itr = 100, T=10, M=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot uncertainty using different trajectories that generated using PCA with NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = collect(range(-10.0, 10.0,length = 100))\n",
    "inp = features(z')\n",
    "trajectories = Array{Float64}(undef,100,itr)\n",
    "for i in 1:itr\n",
    "\tm1 = re(all_chain[:,i])\n",
    "\tout = m1(inp)\n",
    "\ttrajectories[:, i] = out'\n",
    "end\n",
    "SubspaceInference.plot_predictive(data_ld, trajectories, z, title=\"With PCA and NUTS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
