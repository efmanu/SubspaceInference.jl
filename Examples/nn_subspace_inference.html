<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Subspace Inference for Deep Neural Networks</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 0.9em;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">Subspace Inference for Deep Neural Networks</h1>
          <h5>Manu Francis</h5>
          <h5>08-02-2021</h5>
        </div>

        <hr />
<h1>Subspace Inference Based Uncertainty Analysis for Deep Neural Networks</h1>
<h3>Bayes&#39; Rule</h3>
<p>Bayes rule is a mathematical formula used to calculate the conditional probability of an event based on prior knowledge about the conditions that is related to the event. Bayes&#39; rule is expressed as:</p>
<p class="math">\[
P(A|B) = \frac{P(B|A)*P(A))}{P(B)}
\]</p>
<p>Where,</p>
<ul>
<li><p><code>P&#40;A|B&#41;</code>: Conditional probability of event <code>A</code> occurring given <code>B</code> and also known as posterior and it is the updated belief about an event.</p>
</li>
<li><p><code>P&#40;B|A&#41;</code>: Conditional probability of event <code>B</code> occurring given <code>A</code>, known as likelihood</p>
</li>
<li><p><code>P&#40;A&#41;</code>  : Probability of event A, known as prior and it is the belief about the event.</p>
</li>
<li><p><code>P&#40;B&#41;</code>  : Probability of event B, known as evidence</p>
</li>
</ul>
<p>The <a href="https://en.wikipedia.org/wiki/Bayes&#37;27_theorem">Wikipedia page</a> clearly describes Bayes&#39; rule with examples.</p>
<h3>Bayesian Inference</h3>
<p>The Bayesian inference depends on Bayes&#39; rule to update belief regarding a probability of an event to occur based on available observations and evidences. According to the book <a href="https://books.google.com.au/books?hl&#61;en&amp;lr&#61;&amp;id&#61;6H_WDwAAQBAJ&amp;oi&#61;fnd&amp;pg&#61;PT8&amp;dq&#61;statistical&#43;rethinking&#43;mcelreath&amp;ots&#61;WhkgJHxQWl&amp;sig&#61;La0bfuicltYRLmx7MpmwOuA17cc&amp;redir_esc&#61;y#v&#61;onepage&amp;q&#61;statistical&#37;20rethinking&#37;20mcelreath&amp;f&#61;false">Statistical Rethinking</a>, Bayesian inference uses Bayes&#39; rule to quantify the uncertainty in model and parameters. <a href="https://jvanderw.une.edu.au/L11introMCMC.pdf">Markov Chain  Monte Carlo Techniques &#40;MCMC&#41;</a> and <a href="https://stanford.edu/~jgrimmer/VariationalFinal.pdf">variational inference &#40;VI&#41;</a> are used for Bayesian inference.</p>
<h3>Julia packages for Bayesian inference</h3>
<p><a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a>, <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH.jl</a>, <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a>, <a href="https://github.com/cscherrer/Soss.jl">Soss.jl</a>, <a href="https://github.com/StanJulia/Stan.jl">Stan.jl</a> are common packages provides Bayesian inference facility. <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a> contains MH, HMC, NUTS etc based MCMC sampler and variational inference based samplers too. Howeverm <a href="https://github.com/TuringLang/AdvancedMH.jl">AdvancedMH.jl</a> or <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a> only allows Bayesian inference with MH and HMC respectively. However, these algorithms can take input from user defined probability density functions for Bayesian inference.</p>
<h3>Bayesian Neural Networks</h3>
<p><img src="img/bnn.png" alt="BNN" /></p>
<p>The Deep Neural Networks &#40;DNN&#41;  belongs to broader category of ANN with more hidden layers to extract more features from the training data which is capable to tackle more and more complex and challenging problems. However, there will be some  uncertainty in DNN parameters and it can be generated by using Bayesian inference. This technique is called as <a href="https://arxiv.org/pdf/1505.05424.pdf">Bayesian Neural Networks&#40;BNN&#41;</a> and this method uses MCMC and VI methods for uncertainty generation. The drawback on BNN is the time to generate the inference, when  the number of parameters in the neural networks &#40;NN &#41;increases, the uncertainty generation of NN parameters using Bayesian concept become more expensive in terms of time.</p>
<h3>Subspace Inference</h3>
<p><a href="https://arxiv.org/abs/1907.07504">Subspace inference</a> method introduced to reduce the inference time in BNN by constructing a smaller subspace of actual NN Parameter space. This subspace is generated from the  principle  components of the deviation matrix of weight updation during training.</p>
<h3>Subspace Inference Algorithm</h3>
<p>The subspace inference uses a pretrained DNN and it is implemented using following steps</p>
<ol>
<li><p>Generate low dimensional subspace</p>
</li>
<li><p>Execute Bayesian inference within this subspace</p>
</li>
<li><p>Transform posterior of lower dimensional subspace to original dimension</p>
</li>
</ol>
<h4>Algorithm for subspace construction</h4>
<p>The subspace of NN model parameters are constructed by following steps:</p>
<ol>
<li><p>Initialize mean parameters to pretrained parameter value, <span class="math">$W_{swa} = W_0$</span></p>
</li>
<li><p>For every epoch <span class="math">$i$</span>   2.1 Update parameter using SGD  2.2 Update mean parameters as  <span class="math">$Wswa = (n*W_{swa} + \frac{W_{i}}{n+1})$</span>, where <span class="math">$n = i/f$</span>. <span class="math">$f$</span> is the weight update frequency  2.3 Calculate parameter deviation, <span class="math">$W_{d} = W_{i}-W_{swa}$</span></p>
</li>
<li><p>Do principle component analysis</p>
</li>
<li><p>Generate projection matrix</p>
</li>
</ol>
<h4>Algorithm for subspace inference</h4>
<ol>
<li><p>Define proposal distribution of subspace</p>
</li>
<li><p>Define prior distribution of subspace</p>
</li>
<li><p>Define likelihood function, here it is a neural network</p>
</li>
<li><p>Sample subspace values using MCMC or VI samplers.</p>
</li>
</ol>
<h3>SubspaceInference.jl Julia package</h3>
<p>The subspace inference method for DNN and ordinary differential equations &#40;ODEs&#41; are implemented as a package named <a href="https://github.com/efmanu/SubspaceInference.jl">SubspaceInference.jl</a> in Julia.  The subspace inference implementation by <a href="https://arxiv.org/abs/1907.07504">Izamailov</a> consider the deviations of last <span class="math">$M$</span> &#40;rank of PCA&#41; columns. We have modified this algorithm by considering all deviation matrix during subspace construction to get more information about the subspace. Moreover, in <a href="https://arxiv.org/abs/1907.07504">Izamailov</a>&#39;s work, the posterior of subspace is updated based on the prior distribution of subspace only. We modified to generate subspace samples based on weight distribution. The prior distribution is defined as function,  and it takes the  subspace as the input  and  throws NN parameters prior distribution as output which is defined in the below pseudo function:</p>


<pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>prior</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>W</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Wswa</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>Pz</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>W</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>The advanced MH and HMC algorithms help to take prior distribution as functions instead of distribution. The <a href="https://github.com/efmanu/SubspaceInference.jl">SubspaceInference.jl</a> can be installed in Julia as:</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Pkg</span><span class='hljl-t'>
</span><span class='hljl-n'>Pkg</span><span class='hljl-oB'>.</span><span class='hljl-nf'>add</span><span class='hljl-p'>(</span><span class='hljl-s'>&quot;https://github.com/efmanu/SubspaceInference.jl&quot;</span><span class='hljl-p'>)</span>
</pre>


<h3>Example of subspace inference with SubspaceInference.jl</h3>
<p>Implementation of subspace inference for a multilayer perceptron with two input and one output  and three hidden layers is discussed in this section by referring <a href="https://github.com/wjmaddox/drbayes">python implementation</a> using the dataset from there. The example implementation is started with using some packages.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>NPZ</span><span class='hljl-p'>,</span><span class='hljl-n'>Plots</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>:</span><span class='hljl-t'> </span><span class='hljl-n'>Data</span><span class='hljl-oB'>.</span><span class='hljl-n'>DataLoader</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>:</span><span class='hljl-t'> </span><span class='hljl-nd'>@epochs</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>BSON</span><span class='hljl-oB'>:</span><span class='hljl-t'> </span><span class='hljl-nd'>@save</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nd'>@load</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Zygote</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Statistics</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>SubspaceInference</span><span class='hljl-p'>;</span>
</pre>


<p>The sample data is loaded from <code>.npy</code> file found in <a href="https://github.com/wjmaddox/drbayes">python implementation</a>.  This data contains two columns and each columns named as <span class="math">$x$</span> and  <span class="math">$y$</span> respectively. The <span class="math">$x$</span> is converted to features using features function. The feature function returns a matrix <span class="math">$f$</span> with two columns. One column will be the <span class="math">$x/2$</span> and the other column will be <span class="math">$(\frac{x}{2})^2$</span>. </p>


<pre class='hljl'>
<span class='hljl-n'>data_ld</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>npzread</span><span class='hljl-p'>(</span><span class='hljl-s'>&quot;data.npy&quot;</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data_ld</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>vcat</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>./</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>./</span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-oB'>.^</span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>f</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>);</span>
</pre>


<p>The input data <span class="math">$f$</span> and the output <span class="math">$y$</span> zipped as <code>50</code> batches and shuffled using DataLoader available with Flux. The <span class="math">$y$</span> from dataset is plotted against <span class="math">$x$</span> as in the below figure.</p>


<pre class='hljl'>
<span class='hljl-n'>data</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'>  </span><span class='hljl-nf'>DataLoader</span><span class='hljl-p'>(</span><span class='hljl-n'>f</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>batchsize</span><span class='hljl-oB'>=</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>shuffle</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-cs'>#plot data</span><span class='hljl-t'>
</span><span class='hljl-nf'>scatter</span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-n'>color</span><span class='hljl-oB'>=</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;red&quot;</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;Dataset&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>legend</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>)</span>
</pre>


<p><img src="img/data_set.png" alt="Dataset" /></p>
<p>A simple multilayer perceptron is created as using Dense layer for implementing subspace inference example. This DNN contains 2 inputs, 1 output and hidden layers of <span class="math">$[200,50,50]$</span> size. All layers other than the output layer contains the <code>ReLu</code> activation function.</p>


<pre class='hljl'>
<span class='hljl-n'>m</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chain</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>200</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'> 
    </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>200</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>),</span><span class='hljl-t'>
</span><span class='hljl-p'>);</span>
</pre>


<p>The mean squared error between input and output data is used as the loss function.</p>


<pre class='hljl'>
<span class='hljl-nf'>L</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>Losses</span><span class='hljl-oB'>.</span><span class='hljl-nf'>mse</span><span class='hljl-p'>(</span><span class='hljl-nf'>m</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-oB'>/</span><span class='hljl-ni'>2</span><span class='hljl-p'>;</span>
</pre>


<p>The Stochastic Gradient Descent&#40;SGD&#41; optimizer with learning rate of  <code>0.01</code> and momentum of <code>0.95</code> is used for updating parameters during DNN training.</p>


<pre class='hljl'>
<span class='hljl-n'>opt</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Momentum</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.01</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.95</span><span class='hljl-p'>);</span>
</pre>


<p>The intialized parameters of DNN is extracted as below:</p>


<pre class='hljl'>
<span class='hljl-n'>ps</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>params</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>);</span>
</pre>


<p>The callback function prints the loss for every training batch.</p>


<pre class='hljl'>
<span class='hljl-nf'>callback</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@show</span><span class='hljl-p'>(</span><span class='hljl-nf'>L</span><span class='hljl-p'>(</span><span class='hljl-n'>X</span><span class='hljl-p'>,</span><span class='hljl-n'>Y</span><span class='hljl-p'>))</span>
</pre>


<p>The initialized DNN is trained for 3000 epochs using <code>Flux.train&#33;</code> function.</p>


<pre class='hljl'>
<span class='hljl-nd'>@epochs</span><span class='hljl-t'> </span><span class='hljl-ni'>3000</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>train!</span><span class='hljl-p'>(</span><span class='hljl-n'>L</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data_ld</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>opt</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cb</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-nf'>callback</span><span class='hljl-p'>())</span>
</pre>


<p>Also, the DNN is trained <code>5</code> different iterations to plot the SGD solutions. The trained network  is saved after the training using <code>BSON</code> package for future use.</p>


<pre class='hljl'>
<span class='hljl-n'>epochs</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>3000</span><span class='hljl-t'>
</span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>5</span><span class='hljl-t'>
   </span><span class='hljl-n'>m</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chain</span><span class='hljl-p'>(</span><span class='hljl-t'>
           </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>200</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
           </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>200</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
           </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
           </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>relu</span><span class='hljl-p'>),</span><span class='hljl-t'>
           </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>),</span><span class='hljl-t'>
   </span><span class='hljl-p'>)</span><span class='hljl-t'>
   </span><span class='hljl-n'>ps</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>params</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>)</span><span class='hljl-t'>
   </span><span class='hljl-nd'>@epochs</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>train!</span><span class='hljl-p'>(</span><span class='hljl-n'>L</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>opt</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cb</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-nf'>callback</span><span class='hljl-p'>())</span><span class='hljl-t'> 
   </span><span class='hljl-nd'>@save</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;model_weights_</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>j</span><span class='hljl-p'>)</span><span class='hljl-s'>.bson&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>These SGD solutions are used as the standard to compare the uncertainties generated by using subspace inference and plotted as using the below code:</p>


<pre class='hljl'>
<span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>inp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>5</span><span class='hljl-t'>
  </span><span class='hljl-nd'>@load</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;model_weights_</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-s'>.bson&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-t'>
  </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>loadparams!</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>m</span><span class='hljl-p'>(</span><span class='hljl-n'>inp</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>out</span><span class='hljl-oB'>&#39;</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trj</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Dict</span><span class='hljl-p'>()</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trj</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;1&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>trajectories</span><span class='hljl-t'>
</span><span class='hljl-n'>SubspaceInference</span><span class='hljl-oB'>.</span><span class='hljl-nf'>plot_predictive</span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>all_trj</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;SGD Solutions&quot;</span><span class='hljl-p'>])</span>
</pre>


<p>This code first generate a collection of data named <code>z</code> between <code>-10.0</code> to <code>10.0</code>.  Then features will be generated as mentioned in the beginning. After that every saved DNN parameters loaded to model using <code>Flux.loadparams&#33;&#40;&#41;</code> function. Using this updated model, output is predicted and saved to <code>trajectories</code> array. After the prediction,  <code>trajectories</code> required to be added to a dictionary variable named <code>all_trj</code> because the <code>plot_predictive&#40;&#41;</code> function support only <code>Dict</code> type. The plotted the SGD solution are shown in below figure.</p>
<p><img src="img/sgd_sol.png" alt="SGD Solutions" /></p>
<p>One of the pretrained model is used for subspace inference based uncertainty analysis. <code>subspace_inference&#40;&#41;</code> function from <a href="https://github.com/efmanu/SubspaceInference.jl">SubspaceInference.jl</a> package used for this analysis. The loss function is modified to accept model as input for subspace inference, because new model parameters will be generated during sampling for the inference. The loss function will be:</p>


<pre class='hljl'>
<span class='hljl-nf'>L1</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-n'>Losses</span><span class='hljl-oB'>.</span><span class='hljl-nf'>mse</span><span class='hljl-p'>(</span><span class='hljl-nf'>m</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>)</span>
</pre>


<p>This example considers subspace size of <code>3</code> and the pretrained model is updated for <code>10</code> epochs for deviation matrix generation. A new column will be added to deviation matrix during every batch training by setting moment update frequency, <code>c</code> as 1. During inference <code>100</code> subspace samples generated by setting <code>itr</code> variable. The subspace inference is generated using <code>RWMH</code> sampling algorithm  with proposal standard deviation of 0.1 as below:</p>


<pre class='hljl'>
<span class='hljl-n'>M</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-t'>
</span><span class='hljl-n'>T</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>10</span><span class='hljl-t'>
</span><span class='hljl-n'>c</span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'>
</span><span class='hljl-n'>σ_z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.1</span><span class='hljl-t'>
</span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-t'>
 </span><span class='hljl-cs'>#cost function</span><span class='hljl-t'>
</span><span class='hljl-n'>all_chain</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>lp</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>W_swa</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>subspace_inference</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>L1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>opt</span><span class='hljl-p'>,</span><span class='hljl-t'>   </span><span class='hljl-n'>σ_z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.1</span><span class='hljl-p'>,</span><span class='hljl-t'>  </span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-n'>itr</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>T</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>c</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>M</span><span class='hljl-oB'>=</span><span class='hljl-n'>M</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>print_freq</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>alg</span><span class='hljl-t'> </span><span class='hljl-oB'>=:</span><span class='hljl-n'>rwmh</span><span class='hljl-p'>);</span>
</pre>


<p>The output of <code>subspace_inference&#40;&#41;</code> having three variables. <code>chn</code> contains the different DNN weight samples generated from subspace samples. <code>lp</code> is the log probability of each sampling. This helps for subspace inference diagnostics. If the values of <code>lp</code> vector is constant, this means that the proposal by the samplers would be rejected.  If this scenario occurs, we have to try with different subspace size and different proposal distributions. The <code>lp</code> values will look like:</p>
<hr />
<p>The effect of weight uncertainty is plotted by predicting output using modified DNN model with weight samples. The model is restructured using <code>re</code> function generated as:</p>


<pre class='hljl'>
<span class='hljl-n'>θ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>re</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>destructure</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>);</span>
</pre>


<p>For every DNN parameter samples, model is restructured and predicted the output for plotting. To plot, new input <span class="math">$z$</span> is generated between  <code>-10</code> to <code>10</code>. This value is converted to features named <code>inp</code> and it will be fed to restructured DNN model from every parameter samples for the prediction. The predicted output is stored to a array named <code>trajectories</code>. After iteration, it is assigned to a dictionary variable as mentioned above.</p>


<pre class='hljl'>
<span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>inp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-n'>itr</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>itr</span><span class='hljl-t'>
  </span><span class='hljl-n'>m1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>re</span><span class='hljl-p'>(</span><span class='hljl-n'>all_chain</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>])</span><span class='hljl-t'>
  </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>m1</span><span class='hljl-p'>(</span><span class='hljl-n'>inp</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>out</span><span class='hljl-oB'>&#39;</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Dict</span><span class='hljl-p'>()</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;1&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>;</span>
</pre>


<p>The effect of DNN parameter uncertainties in output prediction using subspace inference is plotted using following line.</p>


<pre class='hljl'>
<span class='hljl-n'>SubspaceInference</span><span class='hljl-oB'>.</span><span class='hljl-nf'>plot_predictive</span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;Plot&quot;</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-p'>)</span>
</pre>


<p>and plotted as in below figure.</p>
<p><img src="img/sub_inference.png" alt="Subspace Inference" /></p>
<p>The light blue shaded area represents the effect of DNN parameter uncertainty in output prediction. The mean of uncertainty prediction is plotted in blue color and the red dots corresponds to data points. It is clear from the above figure that the uncertainty is higher in non data areas.</p>
<h3>Effect of different subspace sizes in uncertainty analysis</h3>
<p>This experiment analysis the effect of subspace size in uncertainty analysis. We considered subspace size <code>M</code> as <code>3</code>, <code>5</code>, <code>10</code> and <code>20</code>. The uncertainty is generated using the following code:</p>


<pre class='hljl'>
<span class='hljl-n'>M</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-ni'>3</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>10</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>20</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-cs'>#Rank of PCA or Maximum columns in deviation matrix</span><span class='hljl-t'>
</span><span class='hljl-n'>T</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-t'> </span><span class='hljl-cs'>#Steps</span><span class='hljl-t'>
</span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Dict</span><span class='hljl-p'>()</span><span class='hljl-t'>
</span><span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>inp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>mi</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>4</span><span class='hljl-t'>
    </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>;</span><span class='hljl-t'>
    </span><span class='hljl-nd'>@load</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;model_weights_</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-s'>.bson&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>;</span><span class='hljl-t'>
    </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>loadparams!</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>);</span><span class='hljl-t'>
    </span><span class='hljl-n'>all_chain</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>lp</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>W_swa</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>subspace_inference</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>L</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>opt</span><span class='hljl-p'>,</span><span class='hljl-t'>
  </span><span class='hljl-n'>σ_z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-t'>  </span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-n'>itr</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>T</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>c</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>M</span><span class='hljl-oB'>=</span><span class='hljl-n'>M</span><span class='hljl-p'>[</span><span class='hljl-n'>mi</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>print_freq</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>alg</span><span class='hljl-t'> </span><span class='hljl-oB'>=:</span><span class='hljl-n'>rwmh</span><span class='hljl-p'>);</span><span class='hljl-t'>    
    
    </span><span class='hljl-n'>trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-n'>itr</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>itr</span><span class='hljl-t'>
        </span><span class='hljl-n'>m1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>re</span><span class='hljl-p'>(</span><span class='hljl-n'>all_chain</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>])</span><span class='hljl-t'>
        </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>m1</span><span class='hljl-p'>(</span><span class='hljl-n'>inp</span><span class='hljl-p'>)</span><span class='hljl-t'>
        </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>out</span><span class='hljl-oB'>&#39;</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>mi</span><span class='hljl-p'>)</span><span class='hljl-s'>&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>;</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>title</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;subspace Size: 3&quot;</span><span class='hljl-p'>,</span><span class='hljl-s'>&quot;subspace Size: 5&quot;</span><span class='hljl-p'>,</span><span class='hljl-s'>&quot;subspace Size: 10&quot;</span><span class='hljl-p'>,</span><span class='hljl-s'>&quot;subspace Size: 20&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-n'>SubspaceInference</span><span class='hljl-oB'>.</span><span class='hljl-nf'>plot_predictive</span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-n'>title</span><span class='hljl-p'>)</span>
</pre>


<p>In this code <code>M</code> is considered as an array with subspace sizes. Above figure illustrates the effect DNN parameter uncertainty that generated with different subspace sizes:</p>
<p><img src="img/com_diff_sub.png" alt="Effect of different subspace sizes" /></p>
<p>Above figure depicts that the uncertainty range is increases with higher subspace sizes.</p>
<h3>Effect of comparison of different proposal deviations</h3>
<p>This focuses on the uncertainty outcomes due to different proposal standard deviations, <code>σ_z</code>. This simulation considers proposal deviations of <code>0.1</code> and <code>1.0</code> and following code is used:</p>


<pre class='hljl'>
<span class='hljl-n'>M</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>10</span><span class='hljl-t'> </span><span class='hljl-cs'>#Rank of PCA or Maximum columns in deviation matrix</span><span class='hljl-t'>
</span><span class='hljl-n'>T</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-t'> </span><span class='hljl-cs'>#Steps</span><span class='hljl-t'>
</span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-t'>
</span><span class='hljl-n'>all_trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Dict</span><span class='hljl-p'>()</span><span class='hljl-t'>
</span><span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>100</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>inp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>features</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>σ_z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nfB'>0.1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>mi</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-t'>
    </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>;</span><span class='hljl-t'>
    </span><span class='hljl-nd'>@load</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;model_weights_</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-s'>.bson&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>;</span><span class='hljl-t'>
    </span><span class='hljl-n'>Flux</span><span class='hljl-oB'>.</span><span class='hljl-nf'>loadparams!</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ps</span><span class='hljl-p'>);</span><span class='hljl-t'>
    </span><span class='hljl-n'>all_chain</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>lp</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>W_swa</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>subspace_inference</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>L</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>opt</span><span class='hljl-p'>,</span><span class='hljl-t'>
  </span><span class='hljl-n'>σ_z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>σ_z</span><span class='hljl-p'>[</span><span class='hljl-n'>mi</span><span class='hljl-p'>],</span><span class='hljl-t'>  </span><span class='hljl-n'>itr</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-n'>itr</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>T</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>c</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>M</span><span class='hljl-oB'>=</span><span class='hljl-n'>M</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>print_freq</span><span class='hljl-oB'>=</span><span class='hljl-n'>T</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>alg</span><span class='hljl-t'> </span><span class='hljl-oB'>=:</span><span class='hljl-n'>rwmh</span><span class='hljl-p'>);</span><span class='hljl-t'>    
    
    </span><span class='hljl-n'>trajectories</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-n'>itr</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>itr</span><span class='hljl-t'>
        </span><span class='hljl-n'>m1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>re</span><span class='hljl-p'>(</span><span class='hljl-n'>all_chain</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>])</span><span class='hljl-t'>
        </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>m1</span><span class='hljl-p'>(</span><span class='hljl-n'>inp</span><span class='hljl-p'>)</span><span class='hljl-t'>
        </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>out</span><span class='hljl-oB'>&#39;</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;</span><span class='hljl-si'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>mi</span><span class='hljl-p'>)</span><span class='hljl-s'>&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>trajectories</span><span class='hljl-p'>;</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>title</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;Std: 0.1&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;Std: 1.0&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-n'>SubspaceInference</span><span class='hljl-oB'>.</span><span class='hljl-nf'>plot_predictive</span><span class='hljl-p'>(</span><span class='hljl-n'>data_ld</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>all_trajectories</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-n'>title</span><span class='hljl-p'>)</span>
</pre>


<p><img src="img/st_comp_sub.png" alt="Effect of different proposal standard deviations" /></p>
<p>The above figure shows that for <code>σ_z &#61; 1.0</code> generates larger uncertainty and it is not fitting mean prediction&#40;blue line&#41; with actual data.</p>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="nn_subspace_inference.jmd">nn_subspace_inference.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.6 on 2021-02-09.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
